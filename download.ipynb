{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code for downloading articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare list of articles to download based on publishing journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPUS_1_PATH = './data/scopus_1.csv'\n",
    "SCOPUS_2_PATH = './data/scopus_2.csv'\n",
    "SCOPUS_3_PATH = './data/scopus_3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(SCOPUS_1_PATH)\n",
    "df_2 = pd.read_csv(SCOPUS_2_PATH)\n",
    "df_3 = pd.read_csv(SCOPUS_3_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Author(s) ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source title</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Art. No.</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>...</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>CODEN</th>\n",
       "      <th>PubMed ID</th>\n",
       "      <th>Language of Original Document</th>\n",
       "      <th>Abbreviated Source Title</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Publication Stage</th>\n",
       "      <th>Open Access</th>\n",
       "      <th>Source</th>\n",
       "      <th>EID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chen Y., Liu A., Cheng X.</td>\n",
       "      <td>57203573569;57203568753;7401754355;</td>\n",
       "      <td>Detection of thermokarst lake drainage events ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Science of the Total Environment</td>\n",
       "      <td>807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STEVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Sci. Total Environ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85116938924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curra-Sánchez E.D., Lara C., Cornejo-D'Ottone ...</td>\n",
       "      <td>57272348800;36502397300;57219281043;8865507700...</td>\n",
       "      <td>Contrasting land-uses in two small river basin...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Science of the Total Environment</td>\n",
       "      <td>806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STEVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Sci. Total Environ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85115798899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Becek K., Yong G.Y.V., Sukri R.S., Lai D.T.C.</td>\n",
       "      <td>25227469700;57323380300;36931212700;57199649884;</td>\n",
       "      <td>Shorea albida Sym. does not regenerate in the ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Forest Ecology and Management</td>\n",
       "      <td>504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FECMD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>For. Ecol. Manage.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Hybrid Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85118490097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haro S., Jesus B., Oiry S., Papaspyrou S., Lar...</td>\n",
       "      <td>57207730674;55884902700;57220084562;6603281099...</td>\n",
       "      <td>Microphytobenthos spatio-temporal dynamics acr...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Science of the Total Environment</td>\n",
       "      <td>804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STEVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Sci. Total Environ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85114704794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nguyen T.T., Pham T.D., Nguyen C.T., Delfos J....</td>\n",
       "      <td>57209166347;57188874343;57254177200;5725417730...</td>\n",
       "      <td>A novel intelligence approach based active and...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Science of the Total Environment</td>\n",
       "      <td>804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STEVA</td>\n",
       "      <td>34517328.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Sci. Total Environ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85114661978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Authors  \\\n",
       "0                          Chen Y., Liu A., Cheng X.   \n",
       "1  Curra-Sánchez E.D., Lara C., Cornejo-D'Ottone ...   \n",
       "2      Becek K., Yong G.Y.V., Sukri R.S., Lai D.T.C.   \n",
       "3  Haro S., Jesus B., Oiry S., Papaspyrou S., Lar...   \n",
       "4  Nguyen T.T., Pham T.D., Nguyen C.T., Delfos J....   \n",
       "\n",
       "                                        Author(s) ID  \\\n",
       "0                57203573569;57203568753;7401754355;   \n",
       "1  57272348800;36502397300;57219281043;8865507700...   \n",
       "2   25227469700;57323380300;36931212700;57199649884;   \n",
       "3  57207730674;55884902700;57220084562;6603281099...   \n",
       "4  57209166347;57188874343;57254177200;5725417730...   \n",
       "\n",
       "                                               Title  Year  \\\n",
       "0  Detection of thermokarst lake drainage events ...  2022   \n",
       "1  Contrasting land-uses in two small river basin...  2022   \n",
       "2  Shorea albida Sym. does not regenerate in the ...  2022   \n",
       "3  Microphytobenthos spatio-temporal dynamics acr...  2022   \n",
       "4  A novel intelligence approach based active and...  2022   \n",
       "\n",
       "                       Source title Volume Issue Art. No. Page start Page end  \\\n",
       "0  Science of the Total Environment    807   NaN   150828        NaN      NaN   \n",
       "1  Science of the Total Environment    806   NaN   150435        NaN      NaN   \n",
       "2     Forest Ecology and Management    504   NaN   119816        NaN      NaN   \n",
       "3  Science of the Total Environment    804   NaN   149983        NaN      NaN   \n",
       "4  Science of the Total Environment    804   NaN   150187        NaN      NaN   \n",
       "\n",
       "          ...          ISBN  CODEN   PubMed ID Language of Original Document  \\\n",
       "0         ...           NaN  STEVA         NaN                       English   \n",
       "1         ...           NaN  STEVA         NaN                       English   \n",
       "2         ...           NaN  FECMD         NaN                       English   \n",
       "3         ...           NaN  STEVA         NaN                       English   \n",
       "4         ...           NaN  STEVA  34517328.0                       English   \n",
       "\n",
       "  Abbreviated Source Title Document Type Publication Stage  \\\n",
       "0      Sci. Total Environ.       Article             Final   \n",
       "1      Sci. Total Environ.       Article             Final   \n",
       "2       For. Ecol. Manage.       Article             Final   \n",
       "3      Sci. Total Environ.       Article             Final   \n",
       "4      Sci. Total Environ.       Article             Final   \n",
       "\n",
       "                    Open Access  Source                 EID  \n",
       "0                           NaN  Scopus  2-s2.0-85116938924  \n",
       "1                           NaN  Scopus  2-s2.0-85115798899  \n",
       "2  All Open Access, Hybrid Gold  Scopus  2-s2.0-85118490097  \n",
       "3                           NaN  Scopus  2-s2.0-85114704794  \n",
       "4                           NaN  Scopus  2-s2.0-85114661978  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([df_1, df_2, df_3])\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of all unique publishers\n",
    "publisher_list = full_df['Publisher'].value_counts().index.tolist()\n",
    "len(publisher_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare a dataset of articles that belong to the same journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of journals with list of articles.\n",
    "journal_dict = {}\n",
    "for idx, row in full_df.iterrows():\n",
    "    info = {}\n",
    "    info['title'] = row['Title']\n",
    "    info['doi'] = row['DOI']\n",
    "    info['open-access'] = row['Open Access']\n",
    "    info['issn'] = row['ISSN']\n",
    "\n",
    "    if row['Publisher'] not in journal_dict.keys():\n",
    "        journal_dict[row['Publisher']] = []\n",
    "\n",
    "    journal_dict[row['Publisher']].append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain information of any failed download requests\n",
    "failed_articles_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare list of journals from elsevier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0R-HVnZuBaTX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elsevier B.V.',\n",
       " 'Elsevier Inc.',\n",
       " 'Elsevier Ltd',\n",
       " 'Elsevier',\n",
       " 'Elsevier GmbH',\n",
       " 'Elsevier Science Inc, New York, NY, United States',\n",
       " 'Elsevier BV',\n",
       " 'Elsevier Science Ltd, Oxford',\n",
       " 'Elsevier Science Ltd, Exeter, United Kingdom',\n",
       " 'Elsevier Masson SAS',\n",
       " 'Elsevier Masson s.r.l.',\n",
       " 'Elsevier; PIER, 3',\n",
       " 'Elsevier Science B.V., Amsterdam',\n",
       " 'Elsevier; Developments in Soil Science, 20',\n",
       " 'Elsevier Sci B.V., Amsterdam, Netherlands']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elsevier_list = [i for i in publisher_list if i.startswith('Elsevier')]\n",
    "elsevier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download all articles from elsevier journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_elsevier(root_path, output_filename, response_type, api_key, doi):\n",
    "    \"\"\"Download articles from elsevier journals\n",
    "\n",
    "    Special Instructions: Most articles require the the download \n",
    "    request sent from an IP address inside Purdue Network. Please login to\n",
    "    Purdue WiFi to run this function and get appropraite results.\n",
    "\n",
    "    Args:\n",
    "        doi (string): DOI string of requested article\n",
    "        api_key (string): ELSEVIER API key to use for authentication\n",
    "        response_type (string): text or html\n",
    "        output_filename (): _description_\n",
    "    \"\"\"\n",
    "    # Article url link\n",
    "    url = 'http://api.elsevier.com/content/article/doi:' + doi + '?view=FULL'\n",
    "    \n",
    "    # HTTP headers for authentication\n",
    "    # https://dev.elsevier.com/tecdoc_api_authentication.html - Read this\n",
    "    headers = {\n",
    "        'X-ELS-APIKEY': '{}'.format(api_key),\n",
    "        'Accept': 'text/{}'.format(response_type)\n",
    "    }\n",
    "    \n",
    "    # Make HTTP Get request\n",
    "    response = requests.get(url, stream=True, headers=headers)\n",
    "    \n",
    "    # Save file \n",
    "    with open('{}/{}.{}'.format(root_path,output_filename, response_type), 'wb') as f:\n",
    "        for chunk in response.iter_content(2048):\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELSEVIER_API_KEY = '85f4783f858cca9e81b30e19d0ba5545'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1ede65556967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Retrieve all articles from the journal and iterate through them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdoi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate through the elsevier journal names\n",
    "for idx, journal in enumerate(elsevier_list):\n",
    "    article_list = journal_dict[journal]\n",
    "    failed_articles_list[journal] = []\n",
    "    \n",
    "    # Retrieve all articles from the journal and iterate through them\n",
    "    for num, article in enumerate(article_list):\n",
    "        sleep(random.choice([1, 3]))\n",
    "        \n",
    "        doi = article['doi']\n",
    "        doi = doi.replace('/', '_')\n",
    "        \n",
    "        # Try to download the file\n",
    "        try:\n",
    "            download_from_elsevier('./', \"{}\".format(doi),  'xml',  ELSEVIER_API_KEY, article['doi'])\n",
    "        except Exception as e:\n",
    "            print('Error while downloading from elsevier:', e)\n",
    "            print('Error for article with doi {}'.format(article['doi']))\n",
    "            failed_articles_list[journal].append(article)\n",
    "        \n",
    "        print(idx + num)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download articles from MDPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdpi_list = [i for i in publisher_list if i.startswith('MDPI')]\n",
    "len(mdpi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_mdpi(root_path, output_file, doi):\n",
    "    \"\"\"Download open access articles from MDPI journal\n",
    "\n",
    "    Args:\n",
    "        output_file (string): _description_\n",
    "        doi (_type_): _description_\n",
    "    \"\"\"\n",
    "    # MDPI Search URL link\n",
    "    url = 'https://www.mdpi.com/search?q=' + urllib.parse.quote_plus(doi)\n",
    "    \n",
    "    # Make HTTP Get request\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse response for the actual article\n",
    "    article_url = response.url\n",
    "    full_text_url = article_url + '/htm'\n",
    "    \n",
    "    # Make HTTP Get request for the full text of the article\n",
    "    resp_full_text = requests.get(full_text_url)\n",
    "    \n",
    "    # Save file\n",
    "    with open('{}/{}.html'.format(root_path, output_file), \"w\", encoding='utf-8') as file:\n",
    "        file.write(str(resp_full_text.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-717c1480a92a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Retrieve all articles from the journal and iterate through them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdoi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate through the elsevier journal names\n",
    "for idx, journal in enumerate(mdpi_list):\n",
    "    article_list = journal_dict[journal]\n",
    "    failed_articles_list[journal] = []\n",
    "    \n",
    "    # Retrieve all articles from the journal and iterate through them\n",
    "    for num, article in enumerate(article_list):\n",
    "        sleep(random.choice([1, 3]))\n",
    "        \n",
    "        doi = article['doi']\n",
    "        file_name = doi.replace('/', '_')\n",
    "        \n",
    "        # Try to download the file\n",
    "        try:\n",
    "            download_from_mdpi(\".\",file_name, \"{}\".format(article['doi']))\n",
    "        except Exception as e:\n",
    "            print('Error while downloading from MDPI:', e)\n",
    "            print('Error for article with doi {}'.format(article['doi']))\n",
    "            failed_articles_list[journal].append(article)\n",
    "        \n",
    "        print(idx + num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "download.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
