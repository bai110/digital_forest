{"cells":[{"cell_type":"markdown","metadata":{"id":"Tbpny6-szFdW"},"source":["## **Custom Embeddings**\n","\n","This notebook should be ideally run on google colab. \n","\n","For Google colab, \n","1. Make sure you have added the shared folder \"digital-forest\". \n","2. Mount the google drive onto the colab environment. \n","    1. Go to the folder icon on the left\n","    2. Click on th folder icon with google drive icon.\n","    3. This should mount the drive.\n","    4. Now all files in your drive are directly accessible in your colab environment.\n","\n","For running on local environment, \n","1. Make sure to change the root path to the local directory.\n","2. If any errors make sure to double check the file directory.\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"MOh1tjjwIZSL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"797LZ0io0gVB"},"source":["## 1. Load the data"]},{"cell_type":"markdown","metadata":{"id":"aAojZyQo0HhN"},"source":["**Note:-** Here the directory should match the directory from your google colab drive. \n","To get this\n","1. Explore the folders in the files section\n","2. Right Click on the folder whose path you woukld like to import.\n","3. Click on Copy Path from the dropdown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pLiDf2shAKx"},"outputs":[],"source":["mdpi_dir = '/content/drive/MyDrive/digital-forest/mdpi'\n","elsevier_dir = '/content/drive/MyDrive/digital-forest/elsevier'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tdZ892CLhRy2"},"outputs":[],"source":["# Get a list of all files in given directory\n","from os import walk\n","mdpi_filenames = next(walk(mdpi_dir), (None, None, []))[2]  # [] if no file\n","elsevier_filenames = next(walk(elsevier_dir), (None, None, []))[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-m0uED0X0nIH","outputId":"d298b7d2-5995-4d90-a210-9880b07dc88d","executionInfo":{"status":"ok","timestamp":1664131201310,"user_tz":240,"elapsed":11,"user":{"displayName":"Xinning Bai","userId":"06848635123555360159"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['10.3390_su12030932.html',\n"," '10.3390_su132111674.html',\n"," '10.3390_rs90201023.html']"]},"metadata":{},"execution_count":4}],"source":["mdpi_filenames[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmoevBuz-Yj7","executionInfo":{"status":"ok","timestamp":1664131201311,"user_tz":240,"elapsed":9,"user":{"displayName":"Xinning Bai","userId":"06848635123555360159"}},"outputId":"f5ec4683-357d-415b-e030-505f526f4075"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['10.1016_0034-4257(95)00228-6.xml',\n"," '10.1016_0168-1923(95)02268-6.xml',\n"," '10.1016_0034-4257(95)00235-9.xml']"]},"metadata":{},"execution_count":5}],"source":["elsevier_filenames[:3]"]},{"cell_type":"markdown","metadata":{"id":"Kk8Vu2-Xh30A"},"source":["## 2. Get text data from all files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ur0gyaFeh5KJ"},"outputs":[],"source":["import imp\n","from bs4 import BeautifulSoup\n","import re\n","import pandas as pd\n","\n","def extract_text_from_html(mdpi_dir, mdpi_file_name):\n","    with open(mdpi_dir + '/' + mdpi_file_name, \"r\", encoding='utf-8') as f:\n","        html_file = f.read()\n","    soup = BeautifulSoup(html_file, 'html.parser')\n","    \n","    article = soup.find('article')\n","    text_list = article.find_all(text=True)\n","    article_text = \" \".join(text_list)\n","    \n","    # Remove \\n characters\n","    clean_text = article_text.replace('\\n', ' ')\n","    # Remove special characters and numbers\n","    clean_text = re.sub('[^.,A-Za-z]+', ' ', clean_text)\n","    # Convert all text to lower\n","    clean_text = clean_text.lower()\n","    \n","    return clean_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCxXpOHj-YkC"},"outputs":[],"source":["def extract_title_from_html(mdpi_dir, mdpi_file_name):\n","    with open(mdpi_dir + '/' + mdpi_file_name, \"r\", encoding='utf-8') as f:\n","        html_file = f.read()\n","    soup = BeautifulSoup(html_file, 'html.parser')\n","    title =  soup.find('h1')\n","    title_name = title.find(text=True)\n","    title_name = title_name.replace('\\n', '')\n","       \n","    return title_name    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4K3OGaU-YkD","executionInfo":{"status":"ok","timestamp":1664131354919,"user_tz":240,"elapsed":146953,"user":{"displayName":"Xinning Bai","userId":"06848635123555360159"}},"outputId":"9eda171e-1aa6-4638-94ad-24cdc7fe045d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error while extracting text for 10.3390_rs90201023.html 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.3390_rs90201024.html 'NoneType' object has no attribute 'find_all'\n"]}],"source":["# Get all the text data from the articles - mdpi\n","rows = [[],[]]\n","mdpi_corpus = []\n","failed_files = []\n","\n","for file_name in mdpi_filenames:\n","    # There might be possible exceptions from extracting text. \n","    # This will catch the exceptions and we can analyze why it failed for some files\n","    try:\n","        title = extract_title_from_html(mdpi_dir, file_name)\n","        extracted_text = extract_text_from_html(mdpi_dir, file_name)\n","        rows = [title, extracted_text]\n","        mdpi_corpus.append(rows)\n","    except Exception as e:\n","        failed_files.append(file_name)\n","        print(\"Error while extracting text for {}\".format(file_name), e)"]},{"cell_type":"code","source":["from google.colab import files\n","dataFrame = pd.DataFrame(mdpi_corpus)\n","dataFrame.columns = ['Title', 'Content']\n","dataFrame.to_csv('Mdpi_text.csv')\n","files.download('Mdpi_text.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"DdYhjigsB8bc","executionInfo":{"status":"ok","timestamp":1664131382341,"user_tz":240,"elapsed":557,"user":{"displayName":"Xinning Bai","userId":"06848635123555360159"}},"outputId":"94b5c106-8aef-406b-bc54-5fff31a95eb5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_664ddcd6-be7b-4aad-a2b4-e39e781b9d3a\", \"Mdpi_text.csv\", 25871738)"]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A5nhWuVl-YkG"},"outputs":[],"source":["def extract_text_from_xml(elsevier_dir, elsevier_file_name):\n","    with open(elsevier_dir + '/' + elsevier_file_name, \"r\", encoding='utf-8') as f:\n","        xml_file = f.read()\n","    soup = BeautifulSoup(xml_file, 'xml')\n","    \n","    article = soup.find('article')\n","    text_list = article.find_all(text=True)\n","    article_text = \" \".join(text_list)\n","        \n","    # Remove \\n characters\n","    clean_text = article_text.replace('\\n', ' ')\n","    # Remove special characters and numbers\n","    clean_text = re.sub('[^.,A-Za-z]+', ' ', clean_text)\n","    # Convert all text to lower\n","    clean_text = clean_text.lower()\n","    \n","    return clean_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lm90vX8A-YkH"},"outputs":[],"source":["def extract_title_from_xml(elsevier_dir, elsevier_file_name):\n","    with open(elsevier_dir + '/' + elsevier_file_name, \"r\", encoding='utf-8') as f:\n","        xml_file = f.read()\n","    soup = BeautifulSoup(xml_file, 'xml')\n","    \n","    title =  soup.find('title')\n","    title_name = title.find_all(text=True)\n","    \n","    return title_name    "]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"85GkYLSo-YkI","executionInfo":{"status":"ok","timestamp":1664133716481,"user_tz":240,"elapsed":298308,"user":{"displayName":"Xinning Bai","userId":"06848635123555360159"}},"outputId":"85097c41-dd44-4007-8e23-9051bbc793fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error while extracting text for 10.1016_0034-4257(95)00228-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_0168-1923(95)02268-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_0034-4257(95)00235-9.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_0034-4257(95)00230-8.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2017.01.020.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2014.09.010.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2015.09.003.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2009.04.008.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2016.08.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2004.12.004.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2019.01.031.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2017.05.007.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2018.05.012.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2018.04.005.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2014.01.012.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2018.12.008.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2014.01.006.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2017.08.012.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2014.08.018.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2018.05.002.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2018.04.008.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2017.03.022.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2015.01.015.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2017.10.023.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2015.07.005.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2018.01.025.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2013.04.005.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2018.04.002.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2014.07.008.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2017.10.015.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2020.108079.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2021.108489.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2021.108653.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2021.108609.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2019.107784.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ancene.2021.100284.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2020.108029.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2021.108407.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2020.108187.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2019.107771.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.apgeog.2003.08.009.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2021.108527.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2021.108328.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2020.108314.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2020.108094.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2019.02.019.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.agrformet.2020.107922.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.atmosres.2020.105245.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.cageo.2021.104737.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.dendro.2019.125648.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2018.07.050.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2015.08.036.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2018.01.042.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.08.057.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.02.039.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.09.034.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.02.045.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.12.041.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2018.01.049.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.06.045.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2016.08.022.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2016.12.017.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2019.02.023.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2016.10.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2016.03.036.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2018.04.042.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.11.024.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2017.10.066.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2015.04.016.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2020.106473.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2020.106287.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2020.106279.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2020.106199.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2019.105932.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2020.106288.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2020.106114.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2019.03.011.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ecolind.2019.105747.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.envdev.2021.100641.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.esd.2013.07.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.esd.2012.10.007.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.esd.2015.04.006.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.geodrs.2018.e00195.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.geodrs.2017.02.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.geodrs.2021.e00411.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.ijsrc.2019.07.003.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.gloplacha.2021.103542.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2016.11.004.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2018.11.009.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2018.04.013.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2017.08.004.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rama.2018.11.007.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2017.07.010.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.pce.2018.03.007.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.pce.2019.03.007.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2003.08.017.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2002.09.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2003.06.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2020.100296.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2021.100484.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2019.04.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2003.11.018.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2003.08.012.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2002.08.002.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2002.09.002.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2020.100457.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2021.100560.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2020.100448.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2019.100264.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2019.03.003.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2002.12.001.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsase.2020.100432.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rse.2003.11.008.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsma.2020.101455.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.sajb.2021.03.035.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.rsma.2021.102054.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.seares.2015.04.004.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(00)00110-3.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(03)00016-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0022-1694(98)00208-X.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(02)00189-X.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(03)00039-7.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(03)00064-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(02)00198-0.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_j.worlddev.2003.06.014.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(96)00121-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(03)00098-1.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(97)00133-8.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(97)00136-3.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(96)00213-1.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(98)00035-2.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(98)00074-1.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(96)00148-4.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(95)00196-4.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_s0034-4257(96)00212-x.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(97)00103-X.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(98)00071-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(96)00117-4.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(03)00141-X.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(98)00090-X.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(97)00041-2.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(99)00082-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(99)00052-8.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0961-9534(00)00040-4.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S1462-9011(00)00006-X.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0034-4257(98)00091-1.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_s1352-2310(97)00267-7.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S1350-4495(99)00044-4.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_s0304-3800(99)00156-8.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0038-092X(99)00044-4.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0273-1177(02)80324-6.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S1352-2310(03)00581-8.xml 'NoneType' object has no attribute 'find_all'\n","Error while extracting text for 10.1016_S0168-1923(03)00061-3.xml 'NoneType' object has no attribute 'find_all'\n"]}],"source":["# Get all the text data from the articles - elsevier\n","rows = [[],[]]\n","elsevier_corpus = []\n","failed_files = []\n","for file_name in elsevier_filenames:\n","    # There might be possible exceptions from extracting text. \n","    # This will catch the exceptions and we can analyze why it failed for some files\n","    try:\n","        title = extract_title_from_xml(elsevier_dir, file_name)\n","        extracted_text = extract_text_from_xml(elsevier_dir, file_name)\n","        rows = [title, extracted_text]\n","        elsevier_corpus.append(rows)\n","    except Exception as e:\n","        failed_files.append(file_name)\n","        print(\"Error while extracting text for {}\".format(file_name), e)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"GEA4yWaC-YkL","executionInfo":{"status":"ok","timestamp":1664133717298,"user_tz":240,"elapsed":842,"user":{"displayName":"Xinning Bai","userId":"06848635123555360159"}},"outputId":"e629d468-18b8-44e9-df26-75616069f1c2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_fe10b5c3-0975-4731-b9dc-a57809c81a06\", \"Elsevier_text.csv\", 43947773)"]},"metadata":{}}],"source":["from google.colab import files\n","dataFrame = pd.DataFrame(elsevier_corpus)\n","dataFrame.columns = ['Title', 'Content']\n","dataFrame.to_csv('Elsevier_text.csv')\n","files.download('Elsevier_text.csv')"]},{"cell_type":"markdown","metadata":{"id":"l8QVy8oi3Rc5"},"source":["## 3. Setup glove embeddings "]},{"cell_type":"markdown","metadata":{"id":"lVpEbJ233XJ_"},"source":["**This is required on google colab as data is not stored permenantly.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8fQO3_zi5pA"},"outputs":[],"source":["!wget https://nlp.stanford.edu/data/glove.6B.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMSfPgTDlC3e"},"outputs":[],"source":["!unzip \"glove.6B.zip\""]},{"cell_type":"markdown","metadata":{"id":"yEBft_l_4Qxc"},"source":["## 4. Setup pipeline to make custom embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-r0b14XYjepu"},"outputs":[],"source":["import gensim\n","from gensim.test.utils import get_tmpfile, datapath\n","from gensim.models import KeyedVectors\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","from gensim.models import Word2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rw4cJwVtjISC"},"outputs":[],"source":["glove_file = datapath('/content/glove.6B.50d.txt')\n","tmp_file = get_tmpfile(\"test_word2vec.txt\")\n","\n","_ = glove2word2vec(glove_file, tmp_file)\n","glove_vectors = KeyedVectors.load_word2vec_format(tmp_file)"]},{"cell_type":"markdown","metadata":{"id":"cFqcw7Dg4mrO"},"source":["### 4.1 Process the corpus to the input format required by Word2Vec algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nyr3Uf8R45uh"},"outputs":[],"source":["import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4c0QPXVme4I"},"outputs":[],"source":["# First we combine all the records into one single string\n","full_text = \" \".join(mdpi_corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpzMSNMbmVqr"},"outputs":[],"source":["sentences = []\n","for document in mdpi_corpus:\n","    # Break down each document in the corpus to list of sentences \n","    sent_list = sent_tokenize(document)\n","    # For each sentence break it into list of words\n","    for sent in sent_list:\n","        word_list = word_tokenize(sent)\n","        sentences.append(word_tokenize(sent))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIv8azmQ-RcD"},"outputs":[],"source":["print(\"We have {} sentences in the corpus\".format(len(sentences)))"]},{"cell_type":"markdown","metadata":{"id":"QK7S53sI_Cth"},"source":["### 4.2 Setup Word2Vec model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1sgZiZGkVy2"},"outputs":[],"source":["# build a word2vec model on your dataset\n","base_model = Word2Vec(size=50, window=5, min_count=3, workers=4)\n","base_model.build_vocab(sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMSbH5b3_V9W"},"outputs":[],"source":["total_examples = base_model.corpus_count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRklNiF-_mg_"},"outputs":[],"source":["# Unique words in the vocabulary\n","len(base_model.wv.vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIqKacNTAJq-"},"outputs":[],"source":["# Statistics of our vocabulary\n","unique_words = set(base_model.wv.vocab.keys()) - set(glove_vectors.vocab.keys())\n","common_words = set(base_model.wv.vocab.keys()).intersection(set(glove_vectors.vocab.keys()))\n","\n","print(\"Unique words to our corpus {}\".format(len(unique_words)))\n","print(\"Common words between corpus and glove {}\".format(len(common_words)))"]},{"cell_type":"markdown","metadata":{"id":"vwJSsE4i_00l"},"source":["### 4.3 Train Word2Vec model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsWC-_ldArbK"},"outputs":[],"source":["# update our model with GloVe's vocabulary & weights\n","base_model.build_vocab([list(glove_vectors.vocab.keys())], update=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvFz4klH_bxd"},"outputs":[],"source":["# train on your data\n","base_model.train(sentences, total_examples=total_examples, epochs=100)\n","base_model_wv = base_model.wv"]},{"cell_type":"markdown","metadata":{"id":"TejmYH0WAzFy"},"source":["### 4.4 Analyze our embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dHzag7fVA4MI"},"outputs":[],"source":["list(unique_words)[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3VgwmeG0BCjp"},"outputs":[],"source":["'geoinform' in common_words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"orj3zSoRt5r_"},"outputs":[],"source":["base_model_wv.most_similar('geoinform')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_mnXcHS-YkX"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}